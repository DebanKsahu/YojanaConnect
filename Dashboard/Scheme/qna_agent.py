from sqlmodel import SQLModel
from pydantic import Field
from langchain.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
from langchain_qdrant import QdrantVectorStore
from datetime import datetime, timezone
from langchain_core.runnables import RunnableLambda

load_dotenv()

class ResponseFormatter(SQLModel):
    """
    Represents a formatted response from the LLM system, along with optional metadata
    like timestamp, user ID, or associated query for tracking or debugging purposes.
    """

    llm_response: str = Field(description="The final response generated by the LLM.")
    timestamp: datetime | None = Field(default_factory= lambda : datetime.now(timezone.utc), description="The time when the response was generated.")
    query: str | None = Field(default=None, description="The original user query that triggered the response.")
    context_used: str | None = Field(default=None, description="The context documents used by the LLM to generate this response.")
    user_data_used: str | None = Field(default=None, description="User-specific data considered in the response.")

llm = ChatGoogleGenerativeAI(
    model = "models/gemini-2.0-flash",
    temperature = 0.5
)
llm_with_structured_output = llm.with_structured_output(ResponseFormatter)


prompt = ChatPromptTemplate.from_messages([
    ("system", """
        You are an expert assistant in Indian government schemes and a skilled policy analyst.
        Your job is to answer user questions clearly and accurately using the provided context and user data.

        RULES TO FOLLOW:
        - ALWAYS use only the given context and user data to answer the question.
        - If the context does not contain an answer, respond: "The provided documents do not contain enough information to answer this question."
        - Personalize answers based on user_data where relevant (e.g., age, income, gender).
        - Do NOT fabricate any facts or schemes not found in the context.

        IMPORTANT:
        - Use a helpful and neutral tone.
        - Do NOT return any placeholder values or template variables like {{context}}, {{user_data}}, etc.
        - If user_data is empty, still answer the question but without personalization.
        - Prefer bullet points or numbered lists for multi-part answers if needed.
    """),
    ("human", """
        Task: Answer the user's question based on the provided context and user profile.

        <question>
        {question}
        </question>

        <context>
        {context}
        </context>

        <user_data>
        {user_data}
        </user_data>
     
        <Answer>
     
        </Answer>
    """)
])

def format_docs(docs: list[Document]) -> str:
    return "\n\n".join(doc.page_content for doc in docs)

def agent_qna_pipeline(scheme_id: int, qdrant: QdrantVectorStore, user_input: str, user_data: str, llm = llm_with_structured_output):

    qdrant_retriver = qdrant.as_retriever(
        search_type = "mmr",
        search_kwargs = {
            'k': 10,
            "filter": {
                "must": [
                    {
                        "key": "scheme_id",         
                        "match": {
                            "value": scheme_id            
                        }
                    }
                ]
            }
        },
    )

    qa_chain = (
        {
            "context":  RunnableLambda(lambda x: format_docs(qdrant_retriver.invoke(user_input))),
            "user_data": RunnableLambda(lambda x: x["user_data"]),
            "question": RunnableLambda(lambda _: user_input)
        }
        | prompt
        | llm
    )

    result = qa_chain.invoke({
        "user_data": user_data
    })
    result = ResponseFormatter.model_validate(result)
    return result